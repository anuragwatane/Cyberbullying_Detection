{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Ensemble prediction_Twitter Data.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "id": "9EzPLTDxEbCU",
        "outputId": "6410d8fd-7f1e-4439-b4e5-1dd223b3a3f9"
      },
      "source": [
        "!pip uninstall scikit-learn -y\n",
        "!pip install -U scikit-learn\n",
        "!pip uninstall imbalanced-learn -y\n",
        "!pip install -U imbalanced-learn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found existing installation: scikit-learn 0.24.2\n",
            "Uninstalling scikit-learn-0.24.2:\n",
            "  Successfully uninstalled scikit-learn-0.24.2\n",
            "Collecting scikit-learn\n",
            "  Using cached scikit_learn-0.24.2-cp37-cp37m-manylinux2010_x86_64.whl (22.3 MB)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (2.2.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.0.1)\n",
            "Installing collected packages: scikit-learn\n",
            "Successfully installed scikit-learn-0.24.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "sklearn"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Found existing installation: imbalanced-learn 0.8.0\n",
            "Uninstalling imbalanced-learn-0.8.0:\n",
            "  Successfully uninstalled imbalanced-learn-0.8.0\n",
            "Collecting imbalanced-learn\n",
            "  Using cached imbalanced_learn-0.8.0-py3-none-any.whl (206 kB)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.0.1)\n",
            "Requirement already satisfied: scikit-learn>=0.24 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (0.24.2)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.19.5)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24->imbalanced-learn) (2.2.0)\n",
            "Installing collected packages: imbalanced-learn\n",
            "Successfully installed imbalanced-learn-0.8.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "imblearn"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "bI6FNZRoH1xX",
        "outputId": "d2a2e761-b6aa-459b-d970-9a9b54584af1"
      },
      "source": [
        "import sklearn\n",
        "sklearn.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'0.24.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "N0XynKm3H7bG",
        "outputId": "e74c6ff8-2998-4840-ddb6-8c5a3d0c0b0e"
      },
      "source": [
        "import imblearn\n",
        "imblearn.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'0.8.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 212
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDCOKO-_E5Tj"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction import text \n",
        "from sklearn.ensemble import VotingClassifier \n",
        "from sklearn.linear_model import LogisticRegression \n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "import random\n",
        "random.seed(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNNDpFpiGAID"
      },
      "source": [
        "Import training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "4uSf1NOkGCBs",
        "outputId": "766e5b64-ed71-46b1-b32a-972a55f08106"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "# Local Machine Path :  One_drive\\BDBA\\Analytics 4\\BERT_Flask_Azure_Deep_Learning\\Datasets\\combined_dataset\\combined_dataset.csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-692939c3-f5a7-4e79-a990-12efba69e3fe\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-692939c3-f5a7-4e79-a990-12efba69e3fe\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving combined_dataset.csv to combined_dataset.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "mu8UjHsUG06N",
        "outputId": "92e3deae-329f-4465-f465-ad1224d8aff3"
      },
      "source": [
        "import io\n",
        "df = pd.read_csv( io.BytesIO( uploaded['combined_dataset.csv'] ) )\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>binary_classes</th>\n",
              "      <th>multiple_classes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>#DhoniKeepsTheGlove | WATCH: Sports Minister K...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NONE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@politico No. We should remember very clearly ...</td>\n",
              "      <td>cyberbullying</td>\n",
              "      <td>HATE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@cricketworldcup Guess who would be the winner...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NONE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Corbyn is too politically intellectual for #Bo...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NONE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>All the best to #TeamIndia for another swimmin...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NONE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13480</th>\n",
              "      <td>Brokeback Mountain was boring.</td>\n",
              "      <td>cyberbullying</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13481</th>\n",
              "      <td>So Brokeback Mountain was really depressing.</td>\n",
              "      <td>cyberbullying</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13482</th>\n",
              "      <td>As I sit here, watching the MTV Movie Awards, ...</td>\n",
              "      <td>cyberbullying</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13483</th>\n",
              "      <td>Ok brokeback mountain is such a horrible movie.</td>\n",
              "      <td>cyberbullying</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13484</th>\n",
              "      <td>Oh, and Brokeback Mountain was a terrible movie.</td>\n",
              "      <td>cyberbullying</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13485 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text  ... multiple_classes\n",
              "0      #DhoniKeepsTheGlove | WATCH: Sports Minister K...  ...             NONE\n",
              "1      @politico No. We should remember very clearly ...  ...             HATE\n",
              "2      @cricketworldcup Guess who would be the winner...  ...             NONE\n",
              "3      Corbyn is too politically intellectual for #Bo...  ...             NONE\n",
              "4      All the best to #TeamIndia for another swimmin...  ...             NONE\n",
              "...                                                  ...  ...              ...\n",
              "13480                     Brokeback Mountain was boring.  ...              NaN\n",
              "13481       So Brokeback Mountain was really depressing.  ...              NaN\n",
              "13482  As I sit here, watching the MTV Movie Awards, ...  ...              NaN\n",
              "13483    Ok brokeback mountain is such a horrible movie.  ...              NaN\n",
              "13484   Oh, and Brokeback Mountain was a terrible movie.  ...              NaN\n",
              "\n",
              "[13485 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 215
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cblQO0bTfjHQ"
      },
      "source": [
        "category_to_binary = {'cyberbullying': 0, 'NOT': 1}\n",
        "df['binary_classes'].replace(category_to_binary, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQEE35CsO8MG"
      },
      "source": [
        "Information about the output classes\n",
        "\n",
        "1 = positive sentiment, 0 = negative sentiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msDUudKZE5Tu"
      },
      "source": [
        "X = df[['text']]\n",
        "y = df[['binary_classes']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36SdnS7HsUdJ",
        "outputId": "a506269f-89fa-4d68-e326-59ee40f2d7da"
      },
      "source": [
        "print(type(X))\n",
        "print(type(y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "<class 'pandas.core.frame.DataFrame'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCMl92Hcgkcd"
      },
      "source": [
        "# Split data in train and test with 0.2 factor\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spjS1VMRordl",
        "outputId": "4f05eace-3dbc-4ca7-a519-67f3a53829d8"
      },
      "source": [
        "print(type(X_train))\n",
        "print(type(y_train))\n",
        "print(type(X_test))\n",
        "print(type(y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "<class 'pandas.core.frame.DataFrame'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzhAHi46iL6x",
        "outputId": "d391dcfd-a762-440a-d3bf-b76d8d620054"
      },
      "source": [
        "print(y_train.shape) \n",
        "print(y_train.value_counts())  # y_train unbalanced: need to be under/oversampled"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10788, 1)\n",
            "binary_classes\n",
            "1                 6256\n",
            "0                 4532\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBxy-q4XE5Tw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa7b7e25-b7c6-4697-f4eb-84e144c2a84a"
      },
      "source": [
        "# Oversample the data\n",
        "print(X_train.shape)\n",
        "\n",
        "ros = RandomOverSampler(random_state=0)\n",
        "X_train_oversampled, y_train_oversampled = ros.fit_resample(X_train, y_train)\n",
        "\n",
        "print(X_train_oversampled.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10788, 1)\n",
            "(12512, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A64WhRx1uGM_",
        "outputId": "b313d841-4253-4c39-b976-b560893b8bb0"
      },
      "source": [
        "print(type(X_train_oversampled))\n",
        "print(type(y_train_oversampled))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "<class 'pandas.core.frame.DataFrame'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIGsgdaLE5Tx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "9a834e2b-cae3-45b1-cfe7-61751346114c"
      },
      "source": [
        "df_train = pd.concat([X_train_oversampled, y_train_oversampled], axis = 1)\n",
        "df_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>binary_classes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Again Congress started abusing PM from day 1. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@hirobotix Of course, at the scent of his mast...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@GOP @realDonaldTrump He’s also lied, cheated,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@VioletIrwin76 Humanity lasted this long, why ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>EVMs were first used in 1982. In 1988, Parliam...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12507</th>\n",
              "      <td>RT @spiderlingdaya: LMAOOO ZENDAYA SAID “ill o...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12508</th>\n",
              "      <td>RT @KylieJenner: KYLIE F*CKING SKIN! wow. \\r\\n...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12509</th>\n",
              "      <td>God, anyway for anyone whos read this far the ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12510</th>\n",
              "      <td>How to fuck your footie career before its even...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12511</th>\n",
              "      <td>I am the only person in the world who thought ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12512 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text  binary_classes\n",
              "0      Again Congress started abusing PM from day 1. ...               0\n",
              "1      @hirobotix Of course, at the scent of his mast...               1\n",
              "2      @GOP @realDonaldTrump He’s also lied, cheated,...               0\n",
              "3      @VioletIrwin76 Humanity lasted this long, why ...               0\n",
              "4      EVMs were first used in 1982. In 1988, Parliam...               1\n",
              "...                                                  ...             ...\n",
              "12507  RT @spiderlingdaya: LMAOOO ZENDAYA SAID “ill o...               0\n",
              "12508  RT @KylieJenner: KYLIE F*CKING SKIN! wow. \\r\\n...               0\n",
              "12509  God, anyway for anyone whos read this far the ...               0\n",
              "12510  How to fuck your footie career before its even...               0\n",
              "12511  I am the only person in the world who thought ...               0\n",
              "\n",
              "[12512 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 224
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04h4MsLU_1SS",
        "outputId": "8ab347c5-6d41-405d-eaf2-ab83c51f1652"
      },
      "source": [
        "print(df_train['binary_classes'].value_counts(dropna=False)) #data balanced after oversampling"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1    6256\n",
            "0    6256\n",
            "Name: binary_classes, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uB7gKXEfE5Ty"
      },
      "source": [
        "X_train = df_train.iloc[:, 0]  # get all rows of the first column\n",
        "y_train = df_train.iloc[:, 1]  # get all rows of the second column"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkoufCgExhKD",
        "outputId": "4fd7fb79-2afa-4a55-d7fa-1994f918fc7e"
      },
      "source": [
        "print(type(X_train))\n",
        "print(X_train.shape)\n",
        "\n",
        "print(type(y_train))\n",
        "print(y_train.shape)\n",
        "\n",
        "print(type(X_test))\n",
        "print(X_test.shape)\n",
        "\n",
        "print(type(y_test))\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.series.Series'>\n",
            "(12512,)\n",
            "<class 'pandas.core.series.Series'>\n",
            "(12512,)\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "(2697, 1)\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "(2697, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9dmUplkwIRe"
      },
      "source": [
        "# convert to pandas series\n",
        "X_test = X_test.squeeze()\n",
        "y_test = y_test.squeeze()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6XFWdH6pC8_",
        "outputId": "4cc589b5-7a43-4409-e9fe-727d4dc39205"
      },
      "source": [
        "print(type(X_train))\n",
        "print(X_train.shape)\n",
        "\n",
        "print(type(y_train))\n",
        "print(y_train.shape)\n",
        "\n",
        "print(type(X_test))\n",
        "print(X_test.shape)\n",
        "\n",
        "print(type(y_test))\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.series.Series'>\n",
            "(12512,)\n",
            "<class 'pandas.core.series.Series'>\n",
            "(12512,)\n",
            "<class 'pandas.core.series.Series'>\n",
            "(2697,)\n",
            "<class 'pandas.core.series.Series'>\n",
            "(2697,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whE7_IdQE5Tz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c712bef9-1052-406f-83e0-8640ac77e642"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer as countvec\n",
        "\n",
        "# Create customized stopping words set by including english stop words and @USER and {{URL}}\n",
        "my_additional_stop_words = {'@USER', '{{URL}}', 'url', 'user'}\n",
        "stop_words = text.ENGLISH_STOP_WORDS.union(my_additional_stop_words)\n",
        "\n",
        "# Bag of Words and delete stopping words\n",
        "countvec = countvec(strip_accents='unicode', stop_words=stop_words, analyzer='word')\n",
        "\n",
        "X_train_counts = countvec.fit_transform(X_train)\n",
        "X_test_counts = countvec.transform(X_test)\n",
        "\n",
        "# Why fit_transform() on train data and transform() on test data?\n",
        "# https://towardsdatascience.com/what-and-why-behind-fit-transform-vs-transform-in-scikit-learn-78f915cf96fe\n",
        "\n",
        "# Initialize classifiers\n",
        "log_clf = LogisticRegression(n_jobs=-1)\n",
        "sgd_clf = SGDClassifier(loss='modified_huber', n_jobs=-1)\n",
        "svm_clf = SVC(probability=True)\n",
        "mnb_clf = MultinomialNB()\n",
        "voting_clf = VotingClassifier( \n",
        "    estimators=[('lr', log_clf), ('svm', svm_clf), ('mnb', mnb_clf)], \n",
        "    voting='soft', n_jobs=-1)\n",
        "\n",
        "#Train and evaluation\n",
        "for clf in (log_clf, svm_clf, mnb_clf, voting_clf):\n",
        "    clf.fit( X_train_counts, y_train )\n",
        "    y_pred = clf.predict(X_test_counts)\n",
        "    print(clf.__class__.__name__, f1_score(y_test, y_pred, average = 'macro')) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression 0.7774494137250483\n",
            "SVC 0.7791690204159132\n",
            "MultinomialNB 0.7148849401810784\n",
            "VotingClassifier 0.7848905890192499\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nH_MQP2BTNrh"
      },
      "source": [
        "##### CountVectorizer + LogisticRegression using Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISLDQCqAE5T2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbfcc07a-572f-4df1-c9cc-78529d99b1b3"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "countvec_loglr_pipe = Pipeline( [ ('vect',countvec), ('lr',log_clf) ] )\n",
        "\n",
        "# Internally CountVectorizer.fit_transform() will be applied to X_train \n",
        "# and then X_train will be passed to LogisticRegression\n",
        "countvec_loglr_pipe.fit(X_train, y_train)\n",
        "\n",
        "# Internally CountVectorizer.transform() will be applied to X_test \n",
        "# and then X_test will be passed to LogisticRegression.predict()\n",
        "y_pred = countvec_loglr_pipe.predict(X_test)\n",
        "\n",
        "print(f\"Logistic Regression F1 Score: {f1_score(y_test, y_pred, average = 'macro')}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logistic Regression F1 Score: 0.7774494137250483\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSzy8cZYQe1b",
        "outputId": "1007f7a7-70c0-486c-db0b-de1c296ac819"
      },
      "source": [
        "# current working directory\n",
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lu1nHfB1VV8Z"
      },
      "source": [
        "Saving CountVectorizer+LogisticRegression model as Pickle file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gm6GMMAUuUo"
      },
      "source": [
        "import pickle\n",
        "\n",
        "model_file_name = \"countvec_loglr.pkl\"\n",
        "\n",
        "with open(model_file_name, 'wb') as picklefile:\n",
        "    pickle.dump(countvec_loglr_pipe, picklefile)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzhqUHq5ViWP"
      },
      "source": [
        "Load CountVectorizer+LogisticRegression model from Pickle file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-FamaX8VhYQ",
        "outputId": "a8ac4c39-4438-4e20-ffd5-1ad973565cd6"
      },
      "source": [
        "with open(model_file_name, 'rb') as trained_model:\n",
        "    countvec_loglr_model = pickle.load(trained_model)\n",
        "\n",
        "text = \"You are bad sexist person\"\n",
        "\n",
        "y_pred = countvec_loglr_model.predict([text])\n",
        "\n",
        "print(y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XbYiXtCzNjy"
      },
      "source": [
        "##### CountVectorizer + SVM using Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttmFBxaSzhLZ",
        "outputId": "51f28ecb-a7ba-4166-89d0-4331dfd71601"
      },
      "source": [
        "countvec_SVM_pipe = Pipeline( [ ('vect',countvec), ('svm',svm_clf) ] )\n",
        "\n",
        "# Internally CountVectorizer.fit_transform() will be applied to X_train \n",
        "# and then X_train will be passed to SVM\n",
        "countvec_SVM_pipe.fit(X_train, y_train)\n",
        "\n",
        "# Internally CountVectorizer.transform() will be applied to X_test \n",
        "# and then X_test will be passed to SVM.predict()\n",
        "y_pred = countvec_SVM_pipe.predict(X_test)\n",
        "\n",
        "print(f\"SVM F1 Score: {f1_score(y_test, y_pred, average = 'macro')}\")\n",
        "\n",
        "# Saving CountVectorizer+SVM model as Pickle file\n",
        "model_file_name = \"countvec_SVM.pkl\"\n",
        "\n",
        "with open(model_file_name, 'wb') as picklefile:\n",
        "    pickle.dump(countvec_SVM_pipe, picklefile)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM F1 Score: 0.7791690204159132\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZU1Afx8q1daJ"
      },
      "source": [
        "Load CountVectorizer + SVM model from Pickle file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMs8sReh1jgd",
        "outputId": "6046ac22-0c30-4405-e51f-c1b18548f491"
      },
      "source": [
        "with open(model_file_name, 'rb') as trained_model:\n",
        "    countvec_SVM_model = pickle.load(trained_model)\n",
        "\n",
        "text = \"You are bad sexist person\"\n",
        "\n",
        "y_pred = countvec_SVM_model.predict([text])\n",
        "\n",
        "print(y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58V6-H8b2GRf"
      },
      "source": [
        "##### CountVectorizer+MultinomialNB using Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EMDGwRz2Zif",
        "outputId": "ad02f07a-11a2-4d35-a064-0f2ebfd19633"
      },
      "source": [
        "countvec_MultinomialNB_pipe = Pipeline( [ ('vect',countvec), ('multiNB',mnb_clf) ] )\n",
        "\n",
        "# Internally CountVectorizer.fit_transform() will be applied to X_train \n",
        "# and then X_train will be passed to MultinomialNB\n",
        "countvec_MultinomialNB_pipe.fit(X_train, y_train)\n",
        "\n",
        "# Internally CountVectorizer.transform() will be applied to X_test \n",
        "# and then X_test will be passed to MultinomialNB.predict()\n",
        "y_pred = countvec_MultinomialNB_pipe.predict(X_test)\n",
        "\n",
        "print(f\"MultinomialNB F1 Score: {f1_score(y_test, y_pred, average = 'macro')}\")\n",
        "\n",
        "# Saving CountVectorizer+MultinomialNB model as Pickle file\n",
        "model_file_name = \"countvec_multiNB.pkl\"\n",
        "\n",
        "with open(model_file_name, 'wb') as picklefile:\n",
        "    pickle.dump(countvec_MultinomialNB_pipe, picklefile)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MultinomialNB F1 Score: 0.7148849401810784\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eY26txKI3Q80"
      },
      "source": [
        "Load CountVectorizer+MultinomialNB model from Pickle file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Q_j4jUT3UfB",
        "outputId": "3f6fff57-5a6a-44bb-ddb6-bd50ab3e059a"
      },
      "source": [
        "with open(model_file_name, 'rb') as trained_model:\n",
        "    countvec_multiNB_model = pickle.load(trained_model)\n",
        "\n",
        "text = \"You are bad sexist person\"\n",
        "\n",
        "y_pred = countvec_multiNB_model.predict([text])\n",
        "\n",
        "print(y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WnsKIbBY-by"
      },
      "source": [
        "##### CountVectorizer+VotingClassifier using Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tF1WzbLnZL0R",
        "outputId": "cafdaa01-c174-4295-fcc3-c226d7f02d7e"
      },
      "source": [
        "voting_clf = VotingClassifier( estimators=[('lr', log_clf), ('svm', svm_clf), ('mnb', mnb_clf)], voting='soft', n_jobs=1)  # gives error when n_jobs=-1\n",
        "# while in the above definition does not give error\n",
        "\n",
        "countvec_voteCLF_pipe = Pipeline( [ ('vect',countvec), ('voteCLF',voting_clf) ] )\n",
        "\n",
        "# Internally CountVectorizer.fit_transform() will be applied to X_train \n",
        "# and then X_train will be passed to VotingClassifier\n",
        "countvec_voteCLF_pipe.fit(X_train, y_train)\n",
        "\n",
        "# Internally CountVectorizer.transform() will be applied to X_test \n",
        "# and then X_test will be passed to VotingClassifier.predict()\n",
        "y_pred = countvec_voteCLF_pipe.predict(X_test)\n",
        "\n",
        "print(f\"Voting Classifier F1 Score: {f1_score(y_test, y_pred, average = 'macro')}\")\n",
        "\n",
        "# Saving CountVectorizer+VotingClassifier model as Pickle file\n",
        "model_file_name = \"countvec_voteCLF.pkl\"\n",
        "\n",
        "with open(model_file_name, 'wb') as picklefile:\n",
        "    pickle.dump(countvec_voteCLF_pipe, picklefile)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Voting Classifier F1 Score: 0.7848905890192499\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pNCQUusc-lU"
      },
      "source": [
        "Load CountVectorizer+VotingClassifier model from Pickle file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UpMGdYQdHR5",
        "outputId": "e4eca68a-2f1a-487f-84a5-9d933120736a"
      },
      "source": [
        "with open(model_file_name, 'rb') as trained_model:\n",
        "    countvec_voteCLF_model = pickle.load(trained_model)\n",
        "\n",
        "text = \"Ok brokeback mountain is such a horrible movie\"\n",
        "\n",
        "y_pred = countvec_voteCLF_model.predict([text])\n",
        "\n",
        "print(y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}